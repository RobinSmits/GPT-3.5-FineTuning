{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.0 Introduction\n",
    "\n",
    "In this notebook we will train and validate an Open LLM model to establish a baseline of the accuracy that can be achieved currently with the available Open LLM's.\n",
    "\n",
    "We will compare this baseline against the GPT-3.5 Turbo accuracy and the accuracies achieved by the 3 smaller Transformer models.\n",
    "\n",
    "The open LLM model that will be used is:\n",
    "* PolyLM 1.7B ([HuggingFace URL](https://huggingface.co/DAMO-NLP-MT/polylm-1.7b))\n",
    "\n",
    "This open LLM model consist of 1.7 billion parameters. The Dutch language was part of the dataset used for pre-training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Modules\n",
    "import evaluate\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from datasets import Dataset, DatasetDict\n",
    "from peft import prepare_model_for_kbit_training, get_peft_model, LoraConfig, TaskType\n",
    "from transformers import (AutoConfig,\n",
    "                          AutoModelForSequenceClassification, \n",
    "                          AutoTokenizer,\n",
    "                          BitsAndBytesConfig,\n",
    "                          DataCollatorWithPadding, \n",
    "                          TrainingArguments, \n",
    "                          Trainer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.0 Load Datasets\n",
    "\n",
    "We will reload the training and validation CSV files that were generated earlier with the notebook 'Prepare_Train_and_Validation_Datasets.ipynb'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3069, 11)\n",
      "(1559, 11)\n"
     ]
    }
   ],
   "source": [
    "# Load Datasets\n",
    "train_df = pd.read_csv('./data/train_df.csv')\n",
    "val_df = pd.read_csv('./data/val_df.csv')\n",
    "\n",
    "# Summary\n",
    "print(train_df.shape)\n",
    "print(val_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>mainSection</th>\n",
       "      <th>published_at</th>\n",
       "      <th>publisher</th>\n",
       "      <th>partisan</th>\n",
       "      <th>url</th>\n",
       "      <th>text_wordcount</th>\n",
       "      <th>max_words_text</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10706318</td>\n",
       "      <td>Ogen als schoteltjes bij de Tachtigjarige Oorlog</td>\n",
       "      <td>Ogen als schoteltjes bij de Tachtigjarige Oorl...</td>\n",
       "      <td>/home</td>\n",
       "      <td>2018-10-07</td>\n",
       "      <td>trouw</td>\n",
       "      <td>True</td>\n",
       "      <td>www.trouw.nl/home/ogen-als-schoteltjes-bij-de-...</td>\n",
       "      <td>539</td>\n",
       "      <td>Ogen als schoteltjes bij de Tachtigjarige Oorl...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12633805</td>\n",
       "      <td>Geen beeld, maar een monument voor Mandela in ...</td>\n",
       "      <td>Geen beeld, maar een monument voor Mandela in ...</td>\n",
       "      <td>/amsterdam</td>\n",
       "      <td>2019-05-10</td>\n",
       "      <td>parool</td>\n",
       "      <td>True</td>\n",
       "      <td>www.parool.nl/amsterdam/geen-beeld-maar-een-mo...</td>\n",
       "      <td>662</td>\n",
       "      <td>Geen beeld, maar een monument voor Mandela in ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7140125</td>\n",
       "      <td>Hoe ga je een onveilige arbeidscultuur zoals i...</td>\n",
       "      <td>Hoe ga je een onveilige arbeidscultuur zoals i...</td>\n",
       "      <td>/</td>\n",
       "      <td>2017-04-18</td>\n",
       "      <td>trouw</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>494</td>\n",
       "      <td>Hoe ga je een onveilige arbeidscultuur zoals i...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4490774</td>\n",
       "      <td>Wetenschappers ontdekken lichtgevende discokikker</td>\n",
       "      <td>Wetenschappers ontdekken lichtgevende discokik...</td>\n",
       "      <td>/</td>\n",
       "      <td>2017-03-14</td>\n",
       "      <td>trouw</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>291</td>\n",
       "      <td>Wetenschappers ontdekken lichtgevende discokik...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10592180</td>\n",
       "      <td>Meer fouten kabinet bij steun aan strijdgroepe...</td>\n",
       "      <td>Meer fouten kabinet bij steun aan strijdgroepe...</td>\n",
       "      <td>/home</td>\n",
       "      <td>2018-09-11</td>\n",
       "      <td>trouw</td>\n",
       "      <td>True</td>\n",
       "      <td>www.trouw.nl/home/meer-fouten-kabinet-bij-steu...</td>\n",
       "      <td>471</td>\n",
       "      <td>Meer fouten kabinet bij steun aan strijdgroepe...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id                                              title  \\\n",
       "0  10706318   Ogen als schoteltjes bij de Tachtigjarige Oorlog   \n",
       "1  12633805  Geen beeld, maar een monument voor Mandela in ...   \n",
       "2   7140125  Hoe ga je een onveilige arbeidscultuur zoals i...   \n",
       "3   4490774  Wetenschappers ontdekken lichtgevende discokikker   \n",
       "4  10592180  Meer fouten kabinet bij steun aan strijdgroepe...   \n",
       "\n",
       "                                                text mainSection published_at  \\\n",
       "0  Ogen als schoteltjes bij de Tachtigjarige Oorl...       /home   2018-10-07   \n",
       "1  Geen beeld, maar een monument voor Mandela in ...  /amsterdam   2019-05-10   \n",
       "2  Hoe ga je een onveilige arbeidscultuur zoals i...           /   2017-04-18   \n",
       "3  Wetenschappers ontdekken lichtgevende discokik...           /   2017-03-14   \n",
       "4  Meer fouten kabinet bij steun aan strijdgroepe...       /home   2018-09-11   \n",
       "\n",
       "  publisher  partisan                                                url  \\\n",
       "0     trouw      True  www.trouw.nl/home/ogen-als-schoteltjes-bij-de-...   \n",
       "1    parool      True  www.parool.nl/amsterdam/geen-beeld-maar-een-mo...   \n",
       "2     trouw      True                                                NaN   \n",
       "3     trouw      True                                                NaN   \n",
       "4     trouw      True  www.trouw.nl/home/meer-fouten-kabinet-bij-steu...   \n",
       "\n",
       "   text_wordcount                                     max_words_text  labels  \n",
       "0             539  Ogen als schoteltjes bij de Tachtigjarige Oorl...       1  \n",
       "1             662  Geen beeld, maar een monument voor Mandela in ...       1  \n",
       "2             494  Hoe ga je een onveilige arbeidscultuur zoals i...       1  \n",
       "3             291  Wetenschappers ontdekken lichtgevende discokik...       1  \n",
       "4             471  Meer fouten kabinet bij steun aan strijdgroepe...       1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Summary\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>mainSection</th>\n",
       "      <th>published_at</th>\n",
       "      <th>publisher</th>\n",
       "      <th>partisan</th>\n",
       "      <th>url</th>\n",
       "      <th>text_wordcount</th>\n",
       "      <th>max_words_text</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9266995</td>\n",
       "      <td>Verdachte dodelijke steekpartijen Maastricht l...</td>\n",
       "      <td>Verdachte dodelijke steekpartijen Maastricht l...</td>\n",
       "      <td>/nieuws</td>\n",
       "      <td>2017-12-18</td>\n",
       "      <td>ad</td>\n",
       "      <td>False</td>\n",
       "      <td>www.ad.nl/binnenland/verdachte-dodelijke-steek...</td>\n",
       "      <td>188</td>\n",
       "      <td>Verdachte dodelijke steekpartijen Maastricht l...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4130077</td>\n",
       "      <td>Honderden arrestaties bij acties tegen mensen ...</td>\n",
       "      <td>Honderden arrestaties bij acties tegen mensen ...</td>\n",
       "      <td>/nieuws</td>\n",
       "      <td>2017-02-11</td>\n",
       "      <td>ad</td>\n",
       "      <td>False</td>\n",
       "      <td>www.ad.nl/buitenland/honderden-arrestaties-bij...</td>\n",
       "      <td>122</td>\n",
       "      <td>Honderden arrestaties bij acties tegen mensen ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11147268</td>\n",
       "      <td>Waarom de 'oudejaarsbonus' voor de jongeren va...</td>\n",
       "      <td>Waarom de 'oudejaarsbonus' voor de jongeren va...</td>\n",
       "      <td>/home</td>\n",
       "      <td>2019-01-20</td>\n",
       "      <td>trouw</td>\n",
       "      <td>True</td>\n",
       "      <td>www.trouw.nl/home/waarom-de-oudejaarsbonus-voo...</td>\n",
       "      <td>262</td>\n",
       "      <td>Waarom de 'oudejaarsbonus' voor de jongeren va...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10749100</td>\n",
       "      <td>Klaar voor de verdediging</td>\n",
       "      <td>Klaar voor de verdedigingOver ruim een week be...</td>\n",
       "      <td>/nieuws</td>\n",
       "      <td>2018-10-16</td>\n",
       "      <td>ad</td>\n",
       "      <td>False</td>\n",
       "      <td>www.ad.nl/binnenland/klaar-voor-de-verdediging...</td>\n",
       "      <td>411</td>\n",
       "      <td>Klaar voor de verdedigingOver ruim een week be...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10700707</td>\n",
       "      <td>Windvlaag grijpt springmatras en doodt 2-jarig...</td>\n",
       "      <td>Windvlaag grijpt springmatras en doodt 2-jarig...</td>\n",
       "      <td>/nieuws</td>\n",
       "      <td>2018-10-05</td>\n",
       "      <td>ad</td>\n",
       "      <td>False</td>\n",
       "      <td>www.ad.nl/buitenland/windvlaag-grijpt-springma...</td>\n",
       "      <td>286</td>\n",
       "      <td>Windvlaag grijpt springmatras en doodt 2-jarig...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id                                              title  \\\n",
       "0   9266995  Verdachte dodelijke steekpartijen Maastricht l...   \n",
       "1   4130077  Honderden arrestaties bij acties tegen mensen ...   \n",
       "2  11147268  Waarom de 'oudejaarsbonus' voor de jongeren va...   \n",
       "3  10749100                          Klaar voor de verdediging   \n",
       "4  10700707  Windvlaag grijpt springmatras en doodt 2-jarig...   \n",
       "\n",
       "                                                text mainSection published_at  \\\n",
       "0  Verdachte dodelijke steekpartijen Maastricht l...     /nieuws   2017-12-18   \n",
       "1  Honderden arrestaties bij acties tegen mensen ...     /nieuws   2017-02-11   \n",
       "2  Waarom de 'oudejaarsbonus' voor de jongeren va...       /home   2019-01-20   \n",
       "3  Klaar voor de verdedigingOver ruim een week be...     /nieuws   2018-10-16   \n",
       "4  Windvlaag grijpt springmatras en doodt 2-jarig...     /nieuws   2018-10-05   \n",
       "\n",
       "  publisher  partisan                                                url  \\\n",
       "0        ad     False  www.ad.nl/binnenland/verdachte-dodelijke-steek...   \n",
       "1        ad     False  www.ad.nl/buitenland/honderden-arrestaties-bij...   \n",
       "2     trouw      True  www.trouw.nl/home/waarom-de-oudejaarsbonus-voo...   \n",
       "3        ad     False  www.ad.nl/binnenland/klaar-voor-de-verdediging...   \n",
       "4        ad     False  www.ad.nl/buitenland/windvlaag-grijpt-springma...   \n",
       "\n",
       "   text_wordcount                                     max_words_text  labels  \n",
       "0             188  Verdachte dodelijke steekpartijen Maastricht l...       0  \n",
       "1             122  Honderden arrestaties bij acties tegen mensen ...       0  \n",
       "2             262  Waarom de 'oudejaarsbonus' voor de jongeren va...       1  \n",
       "3             411  Klaar voor de verdedigingOver ruim een week be...       0  \n",
       "4             286  Windvlaag grijpt springmatras en doodt 2-jarig...       0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Summary\n",
    "val_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.0 Process Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Proces DataFrame to DataSet function.\n",
    "def process_dataset(tokenizer):\n",
    "    # Tokenize Helper\n",
    "    def preprocess_function(examples):\n",
    "        return tokenizer(examples[\"text\"], truncation = True)\n",
    "\n",
    "    # Create DataSets\n",
    "    tdf = pd.DataFrame({\"text\": train_df.max_words_text.values, \"label\": train_df.labels.values})\n",
    "    vdf = pd.DataFrame({\"text\": val_df.max_words_text.values, \"label\": val_df.labels.values})\n",
    "    tds = Dataset.from_pandas(tdf)\n",
    "    vds = Dataset.from_pandas(vdf)\n",
    "\n",
    "    ds = DatasetDict()\n",
    "    ds['train'] = tds\n",
    "    ds['validation'] = vds\n",
    "\n",
    "    # Tokenize Text\n",
    "    ds = ds.map(preprocess_function, batched = True)\n",
    "\n",
    "    # Summary\n",
    "    print(ds)\n",
    "\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.0 Evaluation Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = evaluate.load(\"accuracy\")\n",
    "\n",
    "task_evaluator = evaluate.evaluator(\"text-classification\")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = np.argmax(predictions, axis = 1)\n",
    "\n",
    "    return metric.compute(predictions = predictions, references = labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.0 Training and Validation on Subset of the Data\n",
    "\n",
    "In this section we will train and validate the Open LLM model on the loaded and processed CSV files.\n",
    "\n",
    "It is very likely that optimizing the hyperparameters could lead to a further improvement in performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 PolyLM 1.7B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "model_name = 'DAMO-NLP-MT/polylm-1.7b'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1fe0b533083d461995e199e6dd45d17a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3069 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe172fc4bfd34435885765662b8d56b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1559 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['text', 'label', 'input_ids', 'attention_mask'],\n",
      "        num_rows: 3069\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['text', 'label', 'input_ids', 'attention_mask'],\n",
      "        num_rows: 1559\n",
      "    })\n",
      "})\n",
      "LlamaTokenizer(name_or_path='DAMO-NLP-MT/polylm-1.7b', vocab_size=256000, model_max_length=2048, is_fast=False, padding_side='right', truncation_side='right', special_tokens={'bos_token': AddedToken(\"<s>\", rstrip=False, lstrip=False, single_word=False, normalized=True), 'eos_token': AddedToken(\"</s>\", rstrip=False, lstrip=False, single_word=False, normalized=True), 'unk_token': AddedToken(\"<unk>\", rstrip=False, lstrip=False, single_word=False, normalized=True), 'pad_token': '</s>'}, clean_up_tokenization_spaces=False)\n"
     ]
    }
   ],
   "source": [
    "# Create Tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name,\n",
    "                                          use_fast = False,\n",
    "                                          legacy = False)\n",
    "tokenizer.pad_token_id = tokenizer.eos_token_id\n",
    "\n",
    "# Set Data Collator\n",
    "data_collator = DataCollatorWithPadding(tokenizer = tokenizer, padding = 'longest')\n",
    "\n",
    "# Tokenize dataset\n",
    "ds = process_dataset(tokenizer)\n",
    "\n",
    "# Summary\n",
    "print(tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To reduce the memory footprint the LLM model will be quantized to 4-bits and then finetuned with a QLoRA setup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of GPT2ForSequenceClassification were not initialized from the model checkpoint at DAMO-NLP-MT/polylm-1.7b and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 12,591,104 || all params: 1,749,676,032 || trainable%: 0.7196248773898732\n",
      "PeftModelForSequenceClassification(\n",
      "  (base_model): LoraModel(\n",
      "    (model): GPT2ForSequenceClassification(\n",
      "      (transformer): GPT2Model(\n",
      "        (wte): Embedding(256000, 2048)\n",
      "        (wpe): Embedding(2048, 2048)\n",
      "        (drop): Dropout(p=0.0, inplace=False)\n",
      "        (h): ModuleList(\n",
      "          (0-23): 24 x GPT2Block(\n",
      "            (ln_1): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
      "            (attn): GPT2Attention(\n",
      "              (c_attn): Linear4bit(\n",
      "                in_features=2048, out_features=6144, bias=True\n",
      "                (lora_dropout): ModuleDict(\n",
      "                  (default): Dropout(p=0.05, inplace=False)\n",
      "                )\n",
      "                (lora_A): ModuleDict(\n",
      "                  (default): Linear(in_features=2048, out_features=64, bias=False)\n",
      "                )\n",
      "                (lora_B): ModuleDict(\n",
      "                  (default): Linear(in_features=64, out_features=6144, bias=False)\n",
      "                )\n",
      "                (lora_embedding_A): ParameterDict()\n",
      "                (lora_embedding_B): ParameterDict()\n",
      "              )\n",
      "              (c_proj): Linear4bit(in_features=2048, out_features=2048, bias=True)\n",
      "              (attn_dropout): Dropout(p=0.0, inplace=False)\n",
      "              (resid_dropout): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "            (ln_2): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
      "            (mlp): GPT2MLP(\n",
      "              (c_fc): Linear4bit(in_features=2048, out_features=8192, bias=True)\n",
      "              (c_proj): Linear4bit(in_features=8192, out_features=2048, bias=True)\n",
      "              (act): FastGELUActivation()\n",
      "              (dropout): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (ln_f): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "      (score): ModulesToSaveWrapper(\n",
      "        (original_module): Linear(in_features=2048, out_features=2, bias=False)\n",
      "        (modules_to_save): ModuleDict(\n",
      "          (default): Linear(in_features=2048, out_features=2, bias=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Create Config\n",
    "config = AutoConfig.from_pretrained(model_name,\n",
    "                                    num_labels = 2,                                                            \n",
    "                                    use_cache = False)\n",
    "\n",
    "# Create Quantization Config\n",
    "quantization_config = BitsAndBytesConfig(load_in_4bit = True,\n",
    "                                         bnb_4bit_use_double_quant = True,\n",
    "                                         bnb_4bit_quant_type = 'nf4',\n",
    "                                         bnb_4bit_compute_dtype = torch.bfloat16)\n",
    "\n",
    "# Create Model\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name,\n",
    "                                                           config = config,\n",
    "                                                           device_map = {\"\":0},\n",
    "                                                           quantization_config = quantization_config)\n",
    "\n",
    "# Set Pad Token Id\n",
    "model.config.pad_token_id = tokenizer.pad_token_id\n",
    "\n",
    "# Enable Gradient Checkpointing\n",
    "model.gradient_checkpointing_enable()\n",
    "\n",
    "# Create LoRA config\n",
    "loraconfig = LoraConfig(r = 64,\n",
    "                        lora_alpha = 16,\n",
    "                        lora_dropout = 0.05,\n",
    "                        bias = 'none',\n",
    "                        task_type = TaskType.SEQ_CLS,\n",
    "                        fan_in_fan_out = True)\n",
    "\n",
    "# Prep for Training\n",
    "model = prepare_model_for_kbit_training(model)\n",
    "\n",
    "# Create LoRA Model\n",
    "model = get_peft_model(model, loraconfig)\n",
    "model.print_trainable_parameters()\n",
    "\n",
    "# Show Model Summary\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "429a03d0ac734ff4925817e256c88287",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/288 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/robin/environments/LLM/lib/python3.10/site-packages/torch/utils/checkpoint.py:434: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6f91669521743758b27944b1bdd425d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/195 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.53938227891922, 'eval_accuracy': 0.7748556767158435, 'eval_runtime': 110.6391, 'eval_samples_per_second': 14.091, 'eval_steps_per_second': 1.762, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/robin/environments/LLM/lib/python3.10/site-packages/torch/utils/checkpoint.py:434: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d651af4cf3f34773b7e422212cf03030",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/195 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.4602004289627075, 'eval_accuracy': 0.8293778062860808, 'eval_runtime': 110.6227, 'eval_samples_per_second': 14.093, 'eval_steps_per_second': 1.763, 'epoch': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/robin/environments/LLM/lib/python3.10/site-packages/torch/utils/checkpoint.py:434: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f47db22813ef4dfb9d3d0aea94cbe985",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/195 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.4003584384918213, 'eval_accuracy': 0.8338678640153945, 'eval_runtime': 110.663, 'eval_samples_per_second': 14.088, 'eval_steps_per_second': 1.762, 'epoch': 3.0}\n",
      "{'train_runtime': 2465.2235, 'train_samples_per_second': 3.735, 'train_steps_per_second': 0.117, 'train_loss': 0.5310058063930936, 'epoch': 3.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=288, training_loss=0.5310058063930936, metrics={'train_runtime': 2465.2235, 'train_samples_per_second': 3.735, 'train_steps_per_second': 0.117, 'train_loss': 0.5310058063930936, 'epoch': 3.0})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set TrainingArguments\n",
    "training_args = TrainingArguments(output_dir = \"polylm_1.7b\",\n",
    "                                  learning_rate = 2.0e-4,\n",
    "                                  per_device_train_batch_size = 8,\n",
    "                                  per_device_eval_batch_size = 8,\n",
    "                                  gradient_accumulation_steps = 4,\n",
    "                                  warmup_steps = 32,\n",
    "                                  bf16 = True,\n",
    "                                  optim = \"paged_adamw_8bit\",                                 \n",
    "                                  num_train_epochs = 3,\n",
    "                                  weight_decay = 0.001,\n",
    "                                  evaluation_strategy = \"epoch\",\n",
    "                                  save_strategy = \"epoch\",\n",
    "                                  load_best_model_at_end = True,\n",
    "                                  metric_for_best_model = 'accuracy',\n",
    "                                  greater_is_better = True)\n",
    "\n",
    "# Set Trainer\n",
    "trainer = Trainer(model = model,\n",
    "                  args = training_args,\n",
    "                  train_dataset = ds[\"train\"],\n",
    "                  eval_dataset = ds[\"validation\"],\n",
    "                  tokenizer = tokenizer,\n",
    "                  data_collator = data_collator,\n",
    "                  compute_metrics = compute_metrics)\n",
    "\n",
    "# Train Model\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After training the PolyLM 1.7B model achieves an accuracy on the validation set of 83.4%."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
